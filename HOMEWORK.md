# HOMEWORK

## 質問設計の観点と意図

本プロジェクトでは、基礎知識から専門分野、さらには時事情報までを含む5つの質問を独自に設計した。
それぞれの質問は、LLM単体の能力とRAG (Retrieval-Augmented Generation)による知識補完の効果を比較・検証するための観点に基づいている。

| 質問 | 設計意図 |
|------|----------|
| 水の沸点は? | 基礎的な一般知識。RAGなしでも答えられるかのベースライン評価。 |
| 2025年5月5日の東京の天気は? | LLMが知識カットオフ後の情報を扱えない問題を明示。RAGの真価を検証。 |
| ハチ公はどこで待ち続けた? | 記憶系雑学。RAGによる補完が妥当な情報を保持できるかの評価。 |
| 電気はなぜ高圧で送るの? | 理解が求められる専門知識。説明力の差を比較。 |
| 2025年5月、東京都内で開催中の展覧会は? | 検索ベースでしか答えられない最新情報。RAG活用の必要性を示す。 |

また、参照文書には意図的に似たが異なる情報 (例：別の液体の沸点、別日の天気、他の忠犬など)を盛り込み、RAGの検索精度とモデルが正確に意味を判別できるかを評価するよう設計した。

## RAGの実装方法と工夫点

### 使用モデル・構成

- **LLM**: [`SakanaAI/TinySwallow-1.5B-Instruct`](https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct)
  - 最大生成トークン数: `1024`
- **埋め込みモデル**: `sentence-transformers/all-MiniLM-L6-v2`
  - 最大シーケンス長: `8192`

### 実装構成

- **文書読み込みと分割**:
  - `LangChain` の `RecursiveCharacterTextSplitter` を使い、句点と改行で文書を意味単位に分割。
- **ベクトル化と類似度検索**:
  - 上記 SentenceTransformer モデルを使って各チャンクを埋め込み化。
  - クエリとの Cosine 類似度で Top-K (K=3)を取得。
  - それぞれの前後1件ずつを結合し、文脈を補強。
- **RAGの提示方法**:
  - LLMには `[参考資料]` を先頭に提示し、参照の明示を強調。
  - system promptで「日本語で回答」「資料を参考に」と明示。

## 結果の分析と考察
- RAGなしの結果は、`output20250504175331/*_output.txt` に保存。
- RAGありの結果は、`output20250504175331/*_with_reference_output.txt` に保存。

### 回答比較概要

| 質問 | RAGなし (LLM単体) | RAGあり (検索＋LLM) | コメント |
|------|----------------------|------------------------|----------|
| 水の沸点は? | ✅ 正答 (100℃) | ✅ 同じく正答 (100℃) | 両者とも明確に対応可能な一般知識。差はほぼなし。 |
| 2025年5月5日の東京の天気は? | ❌ 回答不能 (「リアルタイム情報にアクセスできない」) | ✅ 天気予報の文章を要約し、正答 (晴時々曇など) | RAGが明確に有利。実世界の最新情報を取り込める。 |
| ハチ公はどこで待ち続けた? | ❌ 誤答 (上野動物園と記載) | ✅ 正答 (渋谷駅) | 記憶に基づく誤りを参照情報で修正できた好例。 |
| 電気はなぜ高圧で送るの? | ✅ 詳細に説明 | ✅ 要点を絞って説明 | 両者とも正答だが、RAGのほうが整理されている。 |
| 2025年5月、東京都内で開催中の展覧会は? | ❌ 回答不能 (最新情報なし) | ✅ 最新の展覧会情報に基づいて正答 | 実時間系の質問で、RAGの効果が明確に出た。 |

### 回答比較詳細

#### 水の沸点は?

| 比較項目 | RAGなし | RAGあり |
|----------|---------|----------|
| 回答 | 標準気圧での沸点を「100℃または212°F」と説明。高度や圧力による変化にも軽く言及。 | 「水の沸点は100度 (1気圧)」と簡潔に回答。 |
| 精度 | ✅ 正確で余談も自然。 | ✅ シンプルだが正確。 |
| コメント | RAGなしの方が情報に厚みがある。RAGありは正確性は保ちつつも簡略。 |
| 評価 | RAGの効果は限定的。 |

#### 東京の天気 (2025年5月5日)

| 比較項目 | RAGなし | RAGあり |
|----------|---------|----------|
| 回答 | 「リアルタイム情報にアクセスできません」と回答。 | 「晴時々曇、最高23度、最低13度、降水確率20%」と具体的に回答。 |
| 精度 | ❌ 回答不能。 | ✅ RAGによって実データが反映。 |
| コメント | 明確にRAGの有効性が発揮された例。カットオフの限界を補完。 |
| 評価 | RAGの必要性が顕著に表れる典型ケース。 |

#### ハチ公はどこで待ち続けた？

| 比較項目 | RAGなし | RAGあり |
|----------|---------|----------|
| 回答 | 上野動物園で過ごした話を中心に、忠犬としての性格や人気を紹介。 | 「渋谷駅で帰りを待ち続けた」と明言。 |
| 精度 | ❌ 事実と異なる。 | ✅ 歴史的に正確。 |
| コメント | ノイズ情報を元にLLMが誤答。RAGにより正答が復元された好例。 |
| 評価 | 参照文書の重要性が高い。RAGの明確な改善効果。 |

#### 電気をなぜ高圧で送るのか？

| 比較項目 | RAGなし | RAGあり |
|----------|---------|----------|
| 回答 | 長距離送電、エネルギー効率、コスト削減、災害時の安定性など多面的に説明。 | 電力損失軽減と電力密度の観点を中心に簡潔に説明。 |
| 精度 | ✅ 正確かつ多面的。 | ✅ 簡潔だが要点は含む。 |
| コメント | RAGなしの方が情報量が多く、詳細だが冗長感あり。RAGありは論点が絞られている。 |
| 評価 | 両者良好だが、RAGの圧縮・要約効果が見られる。用途によって好みが分かれる。 |

#### 東京都内の展覧会 (2025年5月)

| 比較項目 | RAGなし | RAGあり |
|----------|---------|----------|
| 回答 | 展覧会の調べ方を列挙 (Web、SNS、新聞など)し、具体名はなし。 | 「西洋絵画どこから見るか展」などを具体的に列挙。 |
| 精度 | ❌ 回答不能 (メタな案内のみ)。 | ✅ 実データに基づき明確に提示。 |
| コメント | RAGがなければ成立しない質問。RAGによって具体性が大幅に向上。 |
| 評価 | RAGの恩恵が大きく、検索補完の重要性が明示された。 |

### 考察
#### RAGが特に有効だったケース
- **未来予測や時事情報** (例：天気、イベント)はRAGなしでは無力。
- **固有名詞や固有地名に関する知識** (例：ハチ公)は、誤解を防ぐのにRAGが重要。
- **専門的な問いに対して、簡潔に本質を押さえる助けになる**。

#### RAGがあまり効果を発揮しなかったケース
- **一般常識レベルの知識** (水の沸点など)はLLM単体でも正確に回答可能。
- **説明が必要な質問**では、RAGよりもLLMの生成能力に依存する部分もある。

#### RAGの価値
RAGの導入により、**知識の外部性を補う**と同時に、**LLMの誤答を修正・補正する効果**が確認された。また、検索によって得られた情報をモデルが要約・再構成できる点も強みである。

## 発展的な改善案

- **検索の精緻化**:
  - 人やLLMによる類似度再評価 (reranking)を導入することで精度を向上。
- **Chunk設計の最適化**:
  - 構文解析や固有表現認識を使い、意味のまとまりを保持した分割へ。
- **評価指標の導入**:
  - BLEU, ROUGE による出力の自動スコア化で定量的評価。
- **複数モデルの比較**:
  - 同一質問・同一参照資料を異なるLLMに投げて比較分析を行うことで、RAGの汎用性を評価可能。
